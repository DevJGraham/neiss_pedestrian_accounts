{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neiss Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/neiss2014.tsv...\n",
      "../data/neiss2015.tsv...\n",
      "../data/neiss2016.tsv...\n",
      "../data/neiss2017.tsv...\n",
      "Exception Caught\n",
      "../data/neiss2017.tsv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sz/hbk1460n5wdbf8wpmtyd24sc0000gn/T/ipykernel_8704/4181277958.py:10: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  print(len(pd.read_csv(path, sep='\\t', encoding='ISO-8859-1')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sz/hbk1460n5wdbf8wpmtyd24sc0000gn/T/ipykernel_8704/4181277958.py:11: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list.append(pd.read_csv(path, sep='\\t', encoding='ISO-8859-1'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/neiss2018.tsv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sz/hbk1460n5wdbf8wpmtyd24sc0000gn/T/ipykernel_8704/4181277958.py:6: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list.append(pd.read_csv(path, sep='\\t'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/neiss2019.tsv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sz/hbk1460n5wdbf8wpmtyd24sc0000gn/T/ipykernel_8704/4181277958.py:6: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list.append(pd.read_csv(path, sep='\\t'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/neiss2020.tsv...\n",
      "../data/neiss2021.tsv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sz/hbk1460n5wdbf8wpmtyd24sc0000gn/T/ipykernel_8704/4181277958.py:6: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list.append(pd.read_csv(path, sep='\\t'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/neiss2022.tsv...\n",
      "../data/neiss2023.tsv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sz/hbk1460n5wdbf8wpmtyd24sc0000gn/T/ipykernel_8704/4181277958.py:6: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list.append(pd.read_csv(path, sep='\\t'))\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "for year in range(2014, 2024):\n",
    "    path = f'../data/neiss{year}.tsv'\n",
    "    print(path, '...', sep='')\n",
    "    try:\n",
    "        df_list.append(pd.read_csv(path, sep='\\t'))\n",
    "    except UnicodeDecodeError:\n",
    "        print('Exception Caught')\n",
    "        print(path, '...', sep='')\n",
    "        print(len(pd.read_csv(path, sep='\\t', encoding='ISO-8859-1')))\n",
    "        df_list.append(pd.read_csv(path, sep='\\t', encoding='ISO-8859-1'))\n",
    "df = pd.concat(df_list, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop records with missing Narrative_1 data\n",
    "df.drop(df[df['Narrative_1'].isnull()].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3520522 entries, 0 to 3520529\n",
      "Data columns (total 25 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   CPSC_Case_Number   object \n",
      " 1   Treatment_Date     object \n",
      " 2   Age                int64  \n",
      " 3   Sex                float64\n",
      " 4   Race               float64\n",
      " 5   Other_Race         object \n",
      " 6   Hispanic           float64\n",
      " 7   Body_Part          float64\n",
      " 8   Diagnosis          float64\n",
      " 9   Other_Diagnosis    object \n",
      " 10  Body_Part_2        float64\n",
      " 11  Diagnosis_2        float64\n",
      " 12  Other_Diagnosis_2  object \n",
      " 13  Disposition        float64\n",
      " 14  Location           float64\n",
      " 15  Fire_Involvement   float64\n",
      " 16  Product_1          float64\n",
      " 17  Product_2          float64\n",
      " 18  Product_3          float64\n",
      " 19  Alcohol            float64\n",
      " 20  Drug               float64\n",
      " 21  Narrative_1        object \n",
      " 22  Stratum            object \n",
      " 23  PSU                float64\n",
      " 24  Weight             float64\n",
      "dtypes: float64(17), int64(1), object(7)\n",
      "memory usage: 698.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/hf_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning Distil-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 15:26:12.859397: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, ClassLabel, Features, Value\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from evaluate import load\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Combine labeled data to make the train/validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_sample_1 = pd.read_csv('ped_accident_labels.csv', index_col='index')\n",
    "labeled_sample_2 = pd.read_csv('performance_df.csv', index_col=0)\n",
    "labeled_sample_3 = pd.read_csv('holdout_labeled.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Narrative_1</th>\n",
       "      <th>Pedestrian Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16YOM PRESENTS AFTER BEING PEDESTRIAN STRUCK W...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55 YOM DX NECK AND BACK PAIN - S/P PT PEDESTRI...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23YOM WITH ELBOW PAIN AFTER RIDING MOPED TO WO...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50YOM W/THORACIC &amp; LUMBAR BACK STRAIN S/P PEDE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>^66YOM PEDESTRIAN WHO JUMPED TO GET OUT OF WAY...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Narrative_1  Pedestrian Label\n",
       "index                                                                     \n",
       "0      16YOM PRESENTS AFTER BEING PEDESTRIAN STRUCK W...                 0\n",
       "1      55 YOM DX NECK AND BACK PAIN - S/P PT PEDESTRI...                 0\n",
       "2      23YOM WITH ELBOW PAIN AFTER RIDING MOPED TO WO...                 0\n",
       "3      50YOM W/THORACIC & LUMBAR BACK STRAIN S/P PEDE...                 1\n",
       "4      ^66YOM PEDESTRIAN WHO JUMPED TO GET OUT OF WAY...                 0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_sample_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Narrative_1</th>\n",
       "      <th>LLM Classification</th>\n",
       "      <th>Human Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>6YOM WHO WAS RIDING HIS BIKE AND LOST CONTROL,...</td>\n",
       "      <td>Pedestrian</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>27 YOM W/HELMET SWERVED BIKE TO AVOID PEDESTRI...</td>\n",
       "      <td>Not Pedestrian</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>49 YOM DX BACK CONTUSION - S/P BICYCLIST STRUC...</td>\n",
       "      <td>Not Pedestrian</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>18YOM W/OPEN FXS OF TIBIA &amp; FIBULA,ABRAS HIP &amp;...</td>\n",
       "      <td>Pedestrian</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>18YOF BIBEMS AFTER STRUCK BY CAR AND PROPELLED...</td>\n",
       "      <td>Pedestrian</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Narrative_1 LLM Classification  \\\n",
       "index                                                                         \n",
       "522    6YOM WHO WAS RIDING HIS BIKE AND LOST CONTROL,...         Pedestrian   \n",
       "116    27 YOM W/HELMET SWERVED BIKE TO AVOID PEDESTRI...     Not Pedestrian   \n",
       "56     49 YOM DX BACK CONTUSION - S/P BICYCLIST STRUC...     Not Pedestrian   \n",
       "72     18YOM W/OPEN FXS OF TIBIA & FIBULA,ABRAS HIP &...         Pedestrian   \n",
       "1273   18YOF BIBEMS AFTER STRUCK BY CAR AND PROPELLED...         Pedestrian   \n",
       "\n",
       "       Human Label  \n",
       "index               \n",
       "522              1  \n",
       "116              0  \n",
       "56               0  \n",
       "72               1  \n",
       "1273             1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_sample_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPSC_Case_Number</th>\n",
       "      <th>Treatment_Date</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Other_Race</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>Body_Part</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Other_Diagnosis</th>\n",
       "      <th>Body_Part_2</th>\n",
       "      <th>Diagnosis_2</th>\n",
       "      <th>Other_Diagnosis_2</th>\n",
       "      <th>Disposition</th>\n",
       "      <th>Location</th>\n",
       "      <th>Fire_Involvement</th>\n",
       "      <th>Product_1</th>\n",
       "      <th>Product_2</th>\n",
       "      <th>Product_3</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Narrative_1</th>\n",
       "      <th>Stratum</th>\n",
       "      <th>PSU</th>\n",
       "      <th>Weight</th>\n",
       "      <th>group</th>\n",
       "      <th>Pedestrian Probability</th>\n",
       "      <th>Human Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1373638</th>\n",
       "      <td>170957638</td>\n",
       "      <td>09/24/2017</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75</td>\n",
       "      <td>62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52YF HELM'D BICYCLIST CRASHED INTO PEDESTRIAN&amp;...</td>\n",
       "      <td>V</td>\n",
       "      <td>21</td>\n",
       "      <td>16.1828</td>\n",
       "      <td>group_a</td>\n",
       "      <td>0.112776</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870136</th>\n",
       "      <td>220159454</td>\n",
       "      <td>01/25/2022</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24 YOF IN MVA , PEDESTRIAN STRUCK AND INJ LEG ...</td>\n",
       "      <td>V</td>\n",
       "      <td>38</td>\n",
       "      <td>17.2223</td>\n",
       "      <td>group_a</td>\n",
       "      <td>0.387114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007698</th>\n",
       "      <td>220705908</td>\n",
       "      <td>06/09/2022</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12YOM BROUGHT IN BY AMBULANCE AFTER A PEDESTRI...</td>\n",
       "      <td>C</td>\n",
       "      <td>37</td>\n",
       "      <td>6.6676</td>\n",
       "      <td>group_a</td>\n",
       "      <td>0.928713</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703697</th>\n",
       "      <td>151238381</td>\n",
       "      <td>11/18/2015</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40 YOM DX DISPLACED FX OF LT TIBIAL SPINE - S/...</td>\n",
       "      <td>V</td>\n",
       "      <td>57</td>\n",
       "      <td>16.5650</td>\n",
       "      <td>group_a</td>\n",
       "      <td>0.299209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849328</th>\n",
       "      <td>160538697</td>\n",
       "      <td>05/12/2016</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>71</td>\n",
       "      <td>LEG/MOUTH PAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25 YOF DX LEG/MOUTH PAIN - S/P PT PEDESTRIAN S...</td>\n",
       "      <td>V</td>\n",
       "      <td>57</td>\n",
       "      <td>14.6504</td>\n",
       "      <td>group_a</td>\n",
       "      <td>0.624338</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CPSC_Case_Number Treatment_Date  Age  Sex  Race Other_Race  Hispanic  \\\n",
       "1373638         170957638     09/24/2017   52    2     0        NaN       NaN   \n",
       "2870136         220159454     01/25/2022   24    2     4        NaN       2.0   \n",
       "3007698         220705908     06/09/2022   12    1     0        NaN       0.0   \n",
       "703697          151238381     11/18/2015   40    1     2        NaN       NaN   \n",
       "849328          160538697     05/12/2016   25    2     2        NaN       NaN   \n",
       "\n",
       "         Body_Part  Diagnosis Other_Diagnosis  Body_Part_2  Diagnosis_2  \\\n",
       "1373638         75         62             NaN          NaN          NaN   \n",
       "2870136         37         64             NaN          NaN          NaN   \n",
       "3007698         75         52             NaN          NaN          NaN   \n",
       "703697          36         57             NaN          NaN          NaN   \n",
       "849328          81         71  LEG/MOUTH PAIN          NaN          NaN   \n",
       "\n",
       "        Other_Diagnosis_2  Disposition  Location  Fire_Involvement  Product_1  \\\n",
       "1373638               NaN            1         4                 0       5040   \n",
       "2870136               NaN            1         4                 0       5040   \n",
       "3007698               NaN            4         4                 0       5040   \n",
       "703697                NaN            1         4                 0       5040   \n",
       "849328                NaN            1         4                 0       5040   \n",
       "\n",
       "         Product_2  Product_3  Alcohol  Drug  \\\n",
       "1373638          0          0      NaN   NaN   \n",
       "2870136          0          0      0.0   0.0   \n",
       "3007698          0          0      0.0   0.0   \n",
       "703697           0          0      NaN   NaN   \n",
       "849328           0          0      NaN   NaN   \n",
       "\n",
       "                                               Narrative_1 Stratum  PSU  \\\n",
       "1373638  52YF HELM'D BICYCLIST CRASHED INTO PEDESTRIAN&...       V   21   \n",
       "2870136  24 YOF IN MVA , PEDESTRIAN STRUCK AND INJ LEG ...       V   38   \n",
       "3007698  12YOM BROUGHT IN BY AMBULANCE AFTER A PEDESTRI...       C   37   \n",
       "703697   40 YOM DX DISPLACED FX OF LT TIBIAL SPINE - S/...       V   57   \n",
       "849328   25 YOF DX LEG/MOUTH PAIN - S/P PT PEDESTRIAN S...       V   57   \n",
       "\n",
       "          Weight    group  Pedestrian Probability  Human Label  \n",
       "1373638  16.1828  group_a                0.112776            0  \n",
       "2870136  17.2223  group_a                0.387114            1  \n",
       "3007698   6.6676  group_a                0.928713            1  \n",
       "703697   16.5650  group_a                0.299209            0  \n",
       "849328   14.6504  group_a                0.624338            0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_sample_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the three labeled samples, only keeping the narrative and the human label\n",
    "train_validation = pd.concat(\n",
    "    [labeled_sample_1[['Narrative_1', 'Pedestrian Label']].rename(columns={'Pedestrian Label': 'Human Label'}),\n",
    "     labeled_sample_2[['Narrative_1', 'Human Label']],\n",
    "     labeled_sample_3[['Narrative_1', 'Human Label']]\n",
    "     ],\n",
    "    axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Holdout Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329568\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Filter further by location codes of interest (e.g., street or highway)\n",
    "filtered_df = df[df['Location'].isin([4, 5])]\n",
    "\n",
    "# ~96,000 samples remain (~76.5 minutes to run locally)\n",
    "print(len(filtered_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Filter narratives that contain relevant keywords related to pedestrian activity or motor vehicle involvement\n",
    "# search_words = [\n",
    "#     \"walking\", \"walk\", \"jogging\", \"jog\", \"running\", \"run\", \"on foot\", \"bystander\",\n",
    "#     \"standing\", \"biking\", \"bike\", \"roller skating\", \"roller skates\", \"skateboarding\",\n",
    "#     \"skateboard\", \"scootering\", \"scooter\", \"pedestr\", \"pedst\", \"struck by\", \"hit by\"\n",
    "# ]\n",
    "\n",
    "# filtered_df = filtered_df[filtered_df['Narrative_1'].str.contains('|'.join(search_words), case=False, na=False)]\n",
    "\n",
    "# # ~470,000 samples contain at least one keyword (~6.25 hours to run locally)\n",
    "# len(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19489\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Focus on narratives that explicitly mention \"pedestrian\", \"struck by\", or \"hit by\"\n",
    "filtered_df = filtered_df[filtered_df['Narrative_1'].str.contains('|'.join([\"pedestr\", \"pedst\", \"struck by\", \"hit by\"]), case=False, na=False)]\n",
    "\n",
    "# ~20,000 high-priority samples (~15 minutes to run locally)\n",
    "print(len(filtered_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This subset of ~20,000 samples contains location-relevant narratives with keywords most likely to reflect pedestrian injuries involving motor vehicles. This will serve as the primary dataset for local experimentation. In future iterations, model weights may be exported and applied at scale on larger datasets using cloud resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19076"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Excluding data that out model will be trained on\n",
    "filtered_df = filtered_df[~filtered_df['Narrative_1'].isin(train_validation['Narrative_1'])]\n",
    "\n",
    "# There are 19,226 samples that are not in our train/validation set\n",
    "# NOTE: Some data in our train_validation set are not in our original filtered_df since the location codes outside of 4 and 5 were not excluded initially\n",
    "len(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask that contains all of the narratives containing pedestrian\n",
    "pedestrian_mask = filtered_df['Narrative_1'].str.contains('pedst|pedestr', case=False, na=False)\n",
    "# Mask containing all of the narratives containing struck by/hit by\n",
    "struck_hit_mask = filtered_df['Narrative_1'].str.contains('struck by|hit by', case=False, na=False)\n",
    "\n",
    "# df containing 50 \"pedestrian\" samples that don't contain \"struck/hit\" by\n",
    "group_a = filtered_df[pedestrian_mask & ~struck_hit_mask].sample(50, random_state=42)\n",
    "\n",
    "# df containing 50 \"struck/hit by\" samples that dont contain \"pedestrian\"\n",
    "group_b = filtered_df[struck_hit_mask & ~pedestrian_mask].sample(50, random_state=42)\n",
    "\n",
    "# df containing 50 samples where both \"pedestrian\" and \"struck/hit by\" are present in the narrative\n",
    "group_c = filtered_df[struck_hit_mask & pedestrian_mask].sample(50, random_state=42)\n",
    "\n",
    "# Creating flags to test the models performance among each group\n",
    "group_a['group'] = 'group_a'\n",
    "group_b['group'] = 'group_b'\n",
    "group_c['group'] = 'group_c'\n",
    "\n",
    "# Holdout set containing all three groups\n",
    "holdout = pd.concat([group_a, group_b, group_c], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPSC_Case_Number</th>\n",
       "      <th>Treatment_Date</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Other_Race</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>Body_Part</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Other_Diagnosis</th>\n",
       "      <th>Body_Part_2</th>\n",
       "      <th>Diagnosis_2</th>\n",
       "      <th>Other_Diagnosis_2</th>\n",
       "      <th>Disposition</th>\n",
       "      <th>Location</th>\n",
       "      <th>Fire_Involvement</th>\n",
       "      <th>Product_1</th>\n",
       "      <th>Product_2</th>\n",
       "      <th>Product_3</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Narrative_1</th>\n",
       "      <th>Stratum</th>\n",
       "      <th>PSU</th>\n",
       "      <th>Weight</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2995637</th>\n",
       "      <td>220649382</td>\n",
       "      <td>05/18/2022</td>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5040.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17YOF PRESENTED TO ED C/O PEDESTRAIN STRUCK, P...</td>\n",
       "      <td>V</td>\n",
       "      <td>57.0</td>\n",
       "      <td>18.1791</td>\n",
       "      <td>group_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964545</th>\n",
       "      <td>160906268</td>\n",
       "      <td>05/17/2016</td>\n",
       "      <td>43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5040.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43YOM W/CHI,FACIAL CONT,ABRAS &amp; PAIN TO ELBOW ...</td>\n",
       "      <td>V</td>\n",
       "      <td>41.0</td>\n",
       "      <td>14.6504</td>\n",
       "      <td>group_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3253168</th>\n",
       "      <td>230424553</td>\n",
       "      <td>04/07/2023</td>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1333.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23YOM PATIENT WAS ON HIS SKATEBOARD ON HIS WAY...</td>\n",
       "      <td>S</td>\n",
       "      <td>47.0</td>\n",
       "      <td>76.8216</td>\n",
       "      <td>group_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313305</th>\n",
       "      <td>230638234</td>\n",
       "      <td>06/10/2023</td>\n",
       "      <td>53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>OSTEOPHYTE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5040.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53YOM BROUGHT IN BY EMS WITH CC OF LEFT FOREAR...</td>\n",
       "      <td>M</td>\n",
       "      <td>76.0</td>\n",
       "      <td>79.7644</td>\n",
       "      <td>group_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316897</th>\n",
       "      <td>170817237</td>\n",
       "      <td>08/03/2017</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25YOM S/P PEDESTRIAN VS CAR ACCID,5PM TODAY,PT...</td>\n",
       "      <td>L</td>\n",
       "      <td>3.0</td>\n",
       "      <td>67.2099</td>\n",
       "      <td>group_a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CPSC_Case_Number Treatment_Date  Age  Sex  Race Other_Race  Hispanic  \\\n",
       "2995637        220649382     05/18/2022   17  2.0   2.0        NaN       0.0   \n",
       "964545         160906268     05/17/2016   43  1.0   0.0        NaN       NaN   \n",
       "3253168        230424553     04/07/2023   23  1.0   5.0        NaN       2.0   \n",
       "3313305        230638234     06/10/2023   53  1.0   2.0        NaN       2.0   \n",
       "1316897        170817237     08/03/2017   25  1.0   2.0        NaN       NaN   \n",
       "\n",
       "         Body_Part  Diagnosis Other_Diagnosis  Body_Part_2  Diagnosis_2  \\\n",
       "2995637       30.0       55.0             NaN          NaN          NaN   \n",
       "964545        75.0       62.0             NaN          NaN          NaN   \n",
       "3253168       76.0       57.0             NaN         88.0         59.0   \n",
       "3313305       87.0       71.0      OSTEOPHYTE          NaN          NaN   \n",
       "1316897       93.0       57.0             NaN          NaN          NaN   \n",
       "\n",
       "        Other_Diagnosis_2  Disposition  Location  Fire_Involvement  Product_1  \\\n",
       "2995637               NaN          1.0       4.0               0.0     5040.0   \n",
       "964545                NaN          1.0       4.0               0.0     5040.0   \n",
       "3253168               NaN          1.0       4.0               0.0     1333.0   \n",
       "3313305               NaN          1.0       4.0               0.0     5040.0   \n",
       "1316897               NaN          1.0       5.0               0.0     1211.0   \n",
       "\n",
       "         Product_2  Product_3  Alcohol  Drug  \\\n",
       "2995637        0.0        0.0      0.0   0.0   \n",
       "964545         0.0        0.0      NaN   NaN   \n",
       "3253168        0.0        0.0      0.0   0.0   \n",
       "3313305        0.0        0.0      0.0   0.0   \n",
       "1316897        0.0        0.0      NaN   NaN   \n",
       "\n",
       "                                               Narrative_1 Stratum   PSU  \\\n",
       "2995637  17YOF PRESENTED TO ED C/O PEDESTRAIN STRUCK, P...       V  57.0   \n",
       "964545   43YOM W/CHI,FACIAL CONT,ABRAS & PAIN TO ELBOW ...       V  41.0   \n",
       "3253168  23YOM PATIENT WAS ON HIS SKATEBOARD ON HIS WAY...       S  47.0   \n",
       "3313305  53YOM BROUGHT IN BY EMS WITH CC OF LEFT FOREAR...       M  76.0   \n",
       "1316897  25YOM S/P PEDESTRIAN VS CAR ACCID,5PM TODAY,PT...       L   3.0   \n",
       "\n",
       "          Weight    group  \n",
       "2995637  18.1791  group_a  \n",
       "964545   14.6504  group_a  \n",
       "3253168  76.8216  group_a  \n",
       "3313305  79.7644  group_a  \n",
       "1316897  67.2099  group_a  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Features({\n",
    "    'text': Value('string'),\n",
    "    'labels': ClassLabel(names=[\"Not Pedestrian\", \"Pedestrian\"])\n",
    "})\n",
    "\n",
    "dataset = Dataset.from_pandas(\n",
    "    df=train_validation.rename(columns={'Narrative_1':'text', 'Human Label': 'labels'}).reset_index(drop=True),\n",
    "    features=features\n",
    ")\n",
    "\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42, stratify_by_column='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 389\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 98\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 389/389 [00:00<00:00, 3690.11 examples/s]\n",
      "Map: 100%|██████████| 98/98 [00:00<00:00, 5421.21 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Initializing tokenizer\n",
    "pretrained_model=\"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n",
    "\n",
    "# defining the tokenization function\n",
    "def tokenize(sample):\n",
    "    return tokenizer(\n",
    "        sample['text'],\n",
    "        # padding='max_length',\n",
    "        truncation=True\n",
    "    )\n",
    "    \n",
    "results = dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "id2label = {0: \"Not Pedestrian\", 1: \"Pedestrian\"}\n",
    "label2id = {\"Not Pedestrian\":0, \"Pedestrian\": 1}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    pretrained_model,\n",
    "    num_labels = 2,\n",
    "    id2label = id2label,\n",
    "    label2id = label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 5,310,722 || all params: 72,265,732 || trainable%: 7.3489\n"
     ]
    }
   ],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type='SEQ_CLS', # Defining the classification type to be Sequence Classification\n",
    "    r=64, # Lora attention dimension (intrinsic rank of the low-rank matricies)\n",
    "    lora_alpha=32, # Alpha Parameter for Lora scaling (like the learning rate)\n",
    "    lora_dropout=0.1, # The dropout probability for Lora layers\n",
    "    target_modules=['q_lin', 'k_lin', 'v_lin', 'ffn.lin1', 'ffn.lin2'] # We will start by allowing the query, key, and value linear layers to be modified by the model\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation metrics\n",
    "accuracy = load(\"accuracy\")\n",
    "precision = load(\"precision\")\n",
    "recall = load(\"recall\")\n",
    "f1_score = load(\"f1\")\n",
    "\n",
    "# Define a metric function for evaluation\n",
    "def compute_metrics(p):\n",
    "    pred = np.argmax(p.predictions, axis=1)\n",
    "    labels = p.label_ids\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=pred, references=labels)['accuracy'],\n",
    "        \"precision\": precision.compute(predictions=pred, references=labels, average='binary')['precision'],\n",
    "        \"recall\": recall.compute(predictions=pred, references=labels, average='binary')['recall'],\n",
    "        \"f1\": f1_score.compute(predictions=pred, references=labels, average='binary')['f1'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 0.0001 # Size of optimization step\n",
    "batch_size = 8 # number of examples processed per optimization step\n",
    "num_epochs = 10 # number of times the model runs through training data\n",
    "weight_decay = 0.1\n",
    "\n",
    "# Defining the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=weight_decay,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True, \n",
    "    save_total_limit=4,\n",
    "    report_to='tensorboard',\n",
    "    do_eval=True, \n",
    "    logging_strategy='epoch',\n",
    "    overwrite_output_dir=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sz/hbk1460n5wdbf8wpmtyd24sc0000gn/T/ipykernel_99229/1096592910.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args, # hyperparameters\n",
    "    train_dataset=results['train'], # training data\n",
    "    eval_dataset=results['test'], # validation data\n",
    "    tokenizer=tokenizer, # The narratives from the training and testing sets are already pre-tokenized. Passing the tokenizer here is primarily used for decoding predictions\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics, # Runs on HuggingFace's EvalPrediction object (see compute metrics notes for how this works)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='490' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [490/490 04:38, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.675900</td>\n",
       "      <td>0.663032</td>\n",
       "      <td>0.581633</td>\n",
       "      <td>0.581633</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.735484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.626000</td>\n",
       "      <td>0.556480</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.718310</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.474300</td>\n",
       "      <td>0.466987</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.859649</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.371400</td>\n",
       "      <td>0.538394</td>\n",
       "      <td>0.806122</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.852713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.308400</td>\n",
       "      <td>0.528038</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.791045</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.854839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.276200</td>\n",
       "      <td>0.613470</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.760563</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.248200</td>\n",
       "      <td>0.620929</td>\n",
       "      <td>0.806122</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.848000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.241200</td>\n",
       "      <td>0.617919</td>\n",
       "      <td>0.806122</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.848000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.192300</td>\n",
       "      <td>0.636749</td>\n",
       "      <td>0.806122</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.848000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.159600</td>\n",
       "      <td>0.662297</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.841270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=490, training_loss=0.35733717217737315, metrics={'train_runtime': 282.9099, 'train_samples_per_second': 13.75, 'train_steps_per_second': 1.732, 'total_flos': 88370077390320.0, 'train_loss': 0.35733717217737315, 'epoch': 10.0})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.optim.adamw.AdamW'>\n"
     ]
    }
   ],
   "source": [
    "print(type(trainer.optimizer.optimizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check: Test model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.68      0.76        41\n",
      "           1       0.80      0.91      0.85        57\n",
      "\n",
      "    accuracy                           0.82        98\n",
      "   macro avg       0.82      0.80      0.80        98\n",
      "weighted avg       0.82      0.82      0.81        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = trainer.model\n",
    "# Move the model to Metal Performance Shaders (MPS), Apple’s optimized framework for fast tensor computations on Mac\n",
    "model.to('mps')\n",
    "\n",
    "# Set the model to evaluation mode (disables dropout and gradient tracking for layers that behave differently during training)\n",
    "model.eval()\n",
    "\n",
    "loader = DataLoader(\n",
    "    results['test'].remove_columns(['text']),\n",
    "    batch_size = 8,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "# Create a list to store the model’s classification predictions\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        batch = {k:v.to('mps') for k,v in batch.items()}\n",
    "        \n",
    "        logits = model(**batch).logits\n",
    "        \n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        y_pred.extend(preds.to('cpu').numpy())\n",
    "        y_true.extend(batch['labels'].to('cpu').numpy())\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
