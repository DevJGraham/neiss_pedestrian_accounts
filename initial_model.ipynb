{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neiss Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/neiss2014.tsv...\n",
      "./data/neiss2015.tsv...\n",
      "./data/neiss2016.tsv...\n",
      "./data/neiss2017.tsv...\n",
      "Exception Caught\n",
      "./data/neiss2017.tsv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sz/hbk1460n5wdbf8wpmtyd24sc0000gn/T/ipykernel_86085/927198845.py:10: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  print(len(pd.read_csv(path, sep='\\t', encoding='ISO-8859-1')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sz/hbk1460n5wdbf8wpmtyd24sc0000gn/T/ipykernel_86085/927198845.py:11: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list.append(pd.read_csv(path, sep='\\t', encoding='ISO-8859-1'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/neiss2018.tsv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sz/hbk1460n5wdbf8wpmtyd24sc0000gn/T/ipykernel_86085/927198845.py:6: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list.append(pd.read_csv(path, sep='\\t'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/neiss2019.tsv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sz/hbk1460n5wdbf8wpmtyd24sc0000gn/T/ipykernel_86085/927198845.py:6: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list.append(pd.read_csv(path, sep='\\t'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/neiss2020.tsv...\n",
      "./data/neiss2021.tsv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sz/hbk1460n5wdbf8wpmtyd24sc0000gn/T/ipykernel_86085/927198845.py:6: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list.append(pd.read_csv(path, sep='\\t'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/neiss2022.tsv...\n",
      "./data/neiss2023.tsv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sz/hbk1460n5wdbf8wpmtyd24sc0000gn/T/ipykernel_86085/927198845.py:6: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list.append(pd.read_csv(path, sep='\\t'))\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "for year in range(2014, 2024):\n",
    "    path = f'./data/neiss{year}.tsv'\n",
    "    print(path, '...', sep='')\n",
    "    try:\n",
    "        df_list.append(pd.read_csv(path, sep='\\t'))\n",
    "    except UnicodeDecodeError:\n",
    "        print('Exception Caught')\n",
    "        print(path, '...', sep='')\n",
    "        print(len(pd.read_csv(path, sep='\\t', encoding='ISO-8859-1')))\n",
    "        df_list.append(pd.read_csv(path, sep='\\t', encoding='ISO-8859-1'))\n",
    "df = pd.concat(df_list, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop records with missing Narrative_1 data\n",
    "df.drop(df[df['Narrative_1'].isnull()].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3520522 entries, 0 to 3520529\n",
      "Data columns (total 25 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   CPSC_Case_Number   object \n",
      " 1   Treatment_Date     object \n",
      " 2   Age                int64  \n",
      " 3   Sex                float64\n",
      " 4   Race               float64\n",
      " 5   Other_Race         object \n",
      " 6   Hispanic           float64\n",
      " 7   Body_Part          float64\n",
      " 8   Diagnosis          float64\n",
      " 9   Other_Diagnosis    object \n",
      " 10  Body_Part_2        float64\n",
      " 11  Diagnosis_2        float64\n",
      " 12  Other_Diagnosis_2  object \n",
      " 13  Disposition        float64\n",
      " 14  Location           float64\n",
      " 15  Fire_Involvement   float64\n",
      " 16  Product_1          float64\n",
      " 17  Product_2          float64\n",
      " 18  Product_3          float64\n",
      " 19  Alcohol            float64\n",
      " 20  Drug               float64\n",
      " 21  Narrative_1        object \n",
      " 22  Stratum            object \n",
      " 23  PSU                float64\n",
      " 24  Weight             float64\n",
      "dtypes: float64(17), int64(1), object(7)\n",
      "memory usage: 698.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def grep_count(pattern):\n",
    "#     return len(df[df['Narrative_1'].str.contains(pattern, na=False, case=False)])\n",
    "\n",
    "# a = grep_count('pedestrian')\n",
    "# b = grep_count('pedes')\n",
    "# c = grep_count('pedest')\n",
    "# d = grep_count('pedestrain')\n",
    "# e = grep_count('struck by')\n",
    "# f = grep_count('hit by')\n",
    "\n",
    "# print(f\"pedestrian: {a}, pedes: {b}, pedest: {c}, pedestrain: {d}, struck by: {e}, hit by: {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only grabbing sample where the narrative contains pedestr or pedst\n",
    "peds = list(df[df['Narrative_1'].str.contains('pedestr|pedst', na=False, case=False)]['Narrative_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1494"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are 1,494 such samples\n",
    "len(peds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 237 human labeled samples to be used for fine-tuning the model\n",
    "# These were randomly sampled from the peds dataset so as to help the model identify tougher to classify samples\n",
    "labeled_sample = pd.read_csv('ped_accident_labels.csv', index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pedestrian Label\n",
       "1    128\n",
       "0    109\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our data are pretty equally distributed with more exmples of Pedestrian accounts (which account for far fewer samples in the overall dataset)\n",
    "labeled_sample['Pedestrian Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Narrative_1</th>\n",
       "      <th>Pedestrian Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16YOM PRESENTS AFTER BEING PEDESTRIAN STRUCK W...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55 YOM DX NECK AND BACK PAIN - S/P PT PEDESTRI...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23YOM WITH ELBOW PAIN AFTER RIDING MOPED TO WO...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50YOM W/THORACIC &amp; LUMBAR BACK STRAIN S/P PEDE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>^66YOM PEDESTRIAN WHO JUMPED TO GET OUT OF WAY...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Narrative_1  Pedestrian Label\n",
       "index                                                                     \n",
       "0      16YOM PRESENTS AFTER BEING PEDESTRIAN STRUCK W...                 0\n",
       "1      55 YOM DX NECK AND BACK PAIN - S/P PT PEDESTRI...                 0\n",
       "2      23YOM WITH ELBOW PAIN AFTER RIDING MOPED TO WO...                 0\n",
       "3      50YOM W/THORACIC & LUMBAR BACK STRAIN S/P PEDE...                 1\n",
       "4      ^66YOM PEDESTRIAN WHO JUMPED TO GET OUT OF WAY...                 0"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the labeled samples with the original dataframe so that if we need to refer to any additional information (such as product code) we can\n",
    "labeled_sample = labeled_sample.merge(df, on='Narrative_1', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Narrative_1</th>\n",
       "      <th>Pedestrian Label</th>\n",
       "      <th>CPSC_Case_Number</th>\n",
       "      <th>Treatment_Date</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Other_Race</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>Body_Part</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Other_Diagnosis</th>\n",
       "      <th>Body_Part_2</th>\n",
       "      <th>Diagnosis_2</th>\n",
       "      <th>Other_Diagnosis_2</th>\n",
       "      <th>Disposition</th>\n",
       "      <th>Location</th>\n",
       "      <th>Fire_Involvement</th>\n",
       "      <th>Product_1</th>\n",
       "      <th>Product_2</th>\n",
       "      <th>Product_3</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Stratum</th>\n",
       "      <th>PSU</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16YOM PRESENTS AFTER BEING PEDESTRIAN STRUCK W...</td>\n",
       "      <td>0</td>\n",
       "      <td>201227717</td>\n",
       "      <td>10/06/2020</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5040.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>V</td>\n",
       "      <td>57.0</td>\n",
       "      <td>15.9992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55 YOM DX NECK AND BACK PAIN - S/P PT PEDESTRI...</td>\n",
       "      <td>0</td>\n",
       "      <td>160206064</td>\n",
       "      <td>01/04/2016</td>\n",
       "      <td>55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NECK/BACK PAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V</td>\n",
       "      <td>57.0</td>\n",
       "      <td>16.1154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23YOM WITH ELBOW PAIN AFTER RIDING MOPED TO WO...</td>\n",
       "      <td>0</td>\n",
       "      <td>231242909.0</td>\n",
       "      <td>12/13/2023</td>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3215.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L</td>\n",
       "      <td>51.0</td>\n",
       "      <td>55.4417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50YOM W/THORACIC &amp; LUMBAR BACK STRAIN S/P PEDE...</td>\n",
       "      <td>1</td>\n",
       "      <td>160333168</td>\n",
       "      <td>02/05/2016</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1684.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V</td>\n",
       "      <td>41.0</td>\n",
       "      <td>15.3480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>^66YOM PEDESTRIAN WHO JUMPED TO GET OUT OF WAY...</td>\n",
       "      <td>0</td>\n",
       "      <td>151107022</td>\n",
       "      <td>09/05/2015</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>PAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V</td>\n",
       "      <td>41.0</td>\n",
       "      <td>15.7762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Narrative_1  Pedestrian Label  \\\n",
       "0  16YOM PRESENTS AFTER BEING PEDESTRIAN STRUCK W...                 0   \n",
       "1  55 YOM DX NECK AND BACK PAIN - S/P PT PEDESTRI...                 0   \n",
       "2  23YOM WITH ELBOW PAIN AFTER RIDING MOPED TO WO...                 0   \n",
       "3  50YOM W/THORACIC & LUMBAR BACK STRAIN S/P PEDE...                 1   \n",
       "4  ^66YOM PEDESTRIAN WHO JUMPED TO GET OUT OF WAY...                 0   \n",
       "\n",
       "  CPSC_Case_Number Treatment_Date  Age  Sex  Race Other_Race  Hispanic  \\\n",
       "0        201227717     10/06/2020   16  1.0   1.0        NaN       2.0   \n",
       "1        160206064     01/04/2016   55  1.0   2.0        NaN       NaN   \n",
       "2      231242909.0     12/13/2023   23  1.0   2.0        NaN       2.0   \n",
       "3        160333168     02/05/2016   50  1.0   0.0        NaN       NaN   \n",
       "4        151107022     09/05/2015   66  1.0   0.0        NaN       NaN   \n",
       "\n",
       "   Body_Part  Diagnosis Other_Diagnosis  Body_Part_2  Diagnosis_2  \\\n",
       "0       87.0       71.0              NS          NaN          NaN   \n",
       "1       89.0       71.0  NECK/BACK PAIN          NaN          NaN   \n",
       "2       32.0       57.0             NaN          NaN          NaN   \n",
       "3       31.0       64.0             NaN          NaN          NaN   \n",
       "4       37.0       71.0            PAIN          NaN          NaN   \n",
       "\n",
       "  Other_Diagnosis_2  Disposition  Location  Fire_Involvement  Product_1  \\\n",
       "0               NaN          1.0       4.0               0.0     5040.0   \n",
       "1               NaN          1.0       4.0               0.0     1329.0   \n",
       "2               NaN          1.0       4.0               0.0     3215.0   \n",
       "3               NaN          1.0       0.0               0.0     1684.0   \n",
       "4               NaN          1.0       4.0               0.0     1871.0   \n",
       "\n",
       "   Product_2  Product_3  Alcohol  Drug Stratum   PSU   Weight  \n",
       "0        0.0        0.0      0.0   0.0       V  57.0  15.9992  \n",
       "1        0.0        0.0      NaN   NaN       V  57.0  16.1154  \n",
       "2        0.0        0.0      0.0   0.0       L  51.0  55.4417  \n",
       "3        0.0        0.0      NaN   NaN       V  41.0  15.3480  \n",
       "4        0.0        0.0      NaN   NaN       V  41.0  15.7762  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning Distil-BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert dataset to huggingface Dataset object\n",
    "\n",
    "**Hugging Face Dataset Objects:** A special data structure that\n",
    "- Is designed for efficient preprocessing and tokenization\n",
    "\n",
    "- Works seamlessly with Hugging Face models and the Trainer API\n",
    "\n",
    "- Supports powerful methods like .map() (for batching transformations)\n",
    "\n",
    "- Automatically handles formatting for training (like batching and shuffling)\n",
    "\n",
    "\n",
    "We then split the data into an 80/20 train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, ClassLabel, Features, Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_sample['Pedestrian Label'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and rename the relevant columns to 'text' and 'labels' for compatibility with Hugging Face models\n",
    "narrative_and_label = labeled_sample[['Narrative_1', 'Pedestrian Label']].rename(columns={'Narrative_1': 'text', 'Pedestrian Label': 'labels'})\n",
    "\n",
    "# Define the data schema, explicitly marking 'text' as a string and 'labels' as classification targets\n",
    "features = Features({\n",
    "    'text': Value('string'), \n",
    "    'labels': ClassLabel(names=[\"Not Pedestrian\", \"Pedestrian\"]) # (allows for stratification)\n",
    "})\n",
    "\n",
    "# Convert the labeled DataFrame into a Hugging Face Dataset with defined schema\n",
    "dataset = Dataset.from_pandas(narrative_and_label, features=features)\n",
    "\n",
    "# Split the dataset into train and test sets (80/20), stratified by labels for balanced class distribution\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42, stratify_by_column='labels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16YOM PRESENTS AFTER BEING PEDESTRIAN STRUCK W...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55 YOM DX NECK AND BACK PAIN - S/P PT PEDESTRI...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23YOM WITH ELBOW PAIN AFTER RIDING MOPED TO WO...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50YOM W/THORACIC &amp; LUMBAR BACK STRAIN S/P PEDE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>^66YOM PEDESTRIAN WHO JUMPED TO GET OUT OF WAY...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>36YOM PEDESTRIAN COMING OUT OF A BUILDING WHEN...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>33YOM PT STATES AROUND 8PM YESTERDAY WAS RIDIN...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>51YOF DRIVER IN MVA THAT STRUCK A PERSON RIDIN...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>28 YOM HAD BEEN UNHELMETED SKATEBOARDING THROU...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>18YOM WAS RIDING HIS ELECTRIC BIKE, WAS STRUCK...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  labels\n",
       "0    16YOM PRESENTS AFTER BEING PEDESTRIAN STRUCK W...       0\n",
       "1    55 YOM DX NECK AND BACK PAIN - S/P PT PEDESTRI...       0\n",
       "2    23YOM WITH ELBOW PAIN AFTER RIDING MOPED TO WO...       0\n",
       "3    50YOM W/THORACIC & LUMBAR BACK STRAIN S/P PEDE...       1\n",
       "4    ^66YOM PEDESTRIAN WHO JUMPED TO GET OUT OF WAY...       0\n",
       "..                                                 ...     ...\n",
       "232  36YOM PEDESTRIAN COMING OUT OF A BUILDING WHEN...       1\n",
       "233  33YOM PT STATES AROUND 8PM YESTERDAY WAS RIDIN...       0\n",
       "234  51YOF DRIVER IN MVA THAT STRUCK A PERSON RIDIN...       0\n",
       "235  28 YOM HAD BEEN UNHELMETED SKATEBOARDING THROU...       1\n",
       "236  18YOM WAS RIDING HIS ELECTRIC BIKE, WAS STRUCK...       0\n",
       "\n",
       "[237 rows x 2 columns]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "narrative_and_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing Data\n",
    "\n",
    "We use the Hugging Face AutoTokenizer to create a DistilBERT-compatible tokenizer that converts each narrative into a format the model can understand (token IDs and attention masks).\n",
    "\n",
    "We define a tokenize function that:\n",
    "- truncates samples to a maximum of 128 tokens if too long\n",
    "- pads samples to 128 tokens when too short\n",
    "\n",
    "We use .map(batched=True) to efficiently apply it to all samples in the Hugging Face Dataset. The batched=True argument speeds up the process by processing multiple samples at once instead of one at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sample):\n",
    "    return tokenizer(sample['text'], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 189/189 [00:00<00:00, 1521.54 examples/s]\n",
      "Map: 100%|██████████| 48/48 [00:00<00:00, 2996.42 examples/s]\n"
     ]
    }
   ],
   "source": [
    "results = dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '11 YOM C/O FACIAL ABRASION AND SHOULDER ABRASION S/P WAS RIDING HIS BIKE IN THE STREET AND WAS HIT BY A CAR. DX: FACIAL ABRASION; SHOULDER ABRASION; AUTOMOBILE VERSUS PEDESTRIAN',\n",
       " 'labels': 1,\n",
       " 'input_ids': [101,\n",
       "  2340,\n",
       "  10930,\n",
       "  2213,\n",
       "  1039,\n",
       "  1013,\n",
       "  1051,\n",
       "  13268,\n",
       "  11113,\n",
       "  8180,\n",
       "  3258,\n",
       "  1998,\n",
       "  3244,\n",
       "  11113,\n",
       "  8180,\n",
       "  3258,\n",
       "  1055,\n",
       "  1013,\n",
       "  1052,\n",
       "  2001,\n",
       "  5559,\n",
       "  2010,\n",
       "  7997,\n",
       "  1999,\n",
       "  1996,\n",
       "  2395,\n",
       "  1998,\n",
       "  2001,\n",
       "  2718,\n",
       "  2011,\n",
       "  1037,\n",
       "  2482,\n",
       "  1012,\n",
       "  1040,\n",
       "  2595,\n",
       "  1024,\n",
       "  13268,\n",
       "  11113,\n",
       "  8180,\n",
       "  3258,\n",
       "  1025,\n",
       "  3244,\n",
       "  11113,\n",
       "  8180,\n",
       "  3258,\n",
       "  1025,\n",
       "  9935,\n",
       "  6431,\n",
       "  14662,\n",
       "  102],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of the output of one sample\n",
    "results['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Classification Model\n",
    "- We are classifying entire inputs/sentences/sequences therefore we are doing a sequence classification task.\n",
    "- Import AutoModelForSequenceClassification class which is instantiated from a pretrained model (distilBERT in this case) \n",
    "- Set up the mapping for the labels for interpretability as we are training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import AutoModelForSequenceClassification since we are trying to classify the entire input (sequence) at once\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping for the models predictions to help with interpretability\n",
    "id2label = {0: \"Not Pedestrian\", 1: \"Pedestrian\"}\n",
    "label2id = {\"Not Pedestrian\":0, \"Pedestrian\": 1}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", \n",
    "    num_labels=2,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-Rank Adaptation\n",
    "\n",
    "- We are using LoRA for fine-tune only a small number of parameters instead of the full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peft: Parameter Efficient Fine-Tuning\n",
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type='SEQ_CLS', # Defining the classification type to be Sequence Classification\n",
    "    r=8, # Lora attention dimension (intrinsic rank of the low-rank matricies)\n",
    "    lora_alpha=32, # Alpha Parameter for Lora scaling (like the learning rate)\n",
    "    lora_dropout=0.1, # The dropout probability for Lora layers\n",
    "    target_modules=['q_lin', 'k_lin', 'v_lin', 'ffn.lin1', 'ffn.lin2'] # We will start by allowing the query, key, and value linear layers to be modified by the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,181,954 || all params: 68,136,964 || trainable%: 1.7347\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, module in model.named_modules():\n",
    "#     print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Configure and Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "# Load evaluation metrics\n",
    "accuracy = load(\"accuracy\")\n",
    "precision = load(\"precision\")\n",
    "recall = load(\"recall\")\n",
    "f1_score = load(\"f1\")\n",
    "\n",
    "# Define a metric function for evaluation\n",
    "def compute_metrics(p):\n",
    "    pred = np.argmax(p.predictions, axis=1)\n",
    "    labels = p.label_ids\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=pred, references=labels)['accuracy'],\n",
    "        \"precision\": precision.compute(predictions=pred, references=labels, average='binary')['precision'],\n",
    "        \"recall\": recall.compute(predictions=pred, references=labels, average='binary')['recall'],\n",
    "        \"f1\": f1_score.compute(predictions=pred, references=labels, average='binary')['f1'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Untrained Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17YOM PRESENTED AT ED C/O OF PEDESTRIAN STRUCK. PT WAS HELMETED AND RIDING A BICYCLE WHEN A CAR HIT HIM HEAD-ON. PT HIT THE WINDSHIELD AGAINST THE FRONT OF HIS BODY AND LEFT SIDE OF HIS FACE.  DENIES ANY LOSS OF CONSCIOUSNESS. CURRENTLY COMPLAINING OF RIGHT-SIDED INGUINAL PAIN.  PT SUSTAINED ABRASIONS TO RIGHT INGUINAL REGION AND RIGHT CHEEK.  DX: PEDESTRIAN INJURED IN TRAFFIC ACCIDENT',\n",
       " '21YOF RIDING A SMALL SCOOTER AND STRUCK BY CAR ON L SIDE, PT WAS THEPEDESTRIAN DX:A L HIP AND KNEE CONTU',\n",
       " '55 YOF PEDESTRIAN WAS STRUCK BY A CYCLIST TRAVELING 15-20MPH.          DX:  TRAUMATIC ICH, EPIDURAL HEMATOMA, RESP FAILURE, SDH.',\n",
       " '50YOM W/THORACIC & LUMBAR BACK STRAIN S/P PEDESTRIAN HIT BY CAR THAT WAS BACKING UP. STATES WAS SITTING IN A CART WHEN HIT.',\n",
       " '13 YOM ***, TRIED TO DODGE PEDESTRIAN & FELL C/O ANKLE PAIN DX TRIPLANE ANKLE FRACTURE']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(25)\n",
    "sample = random.sample(list(labeled_sample['Narrative_1'].values), 5)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained model predictions\n",
      "----------------------------\n",
      "17YOM PRESENTED AT ED C/O OF PEDESTRIAN STRUCK. PT WAS HELMETED AND RIDING A BICYCLE WHEN A CAR HIT HIM HEAD-ON. PT HIT THE WINDSHIELD AGAINST THE FRONT OF HIS BODY AND LEFT SIDE OF HIS FACE.  DENIES ANY LOSS OF CONSCIOUSNESS. CURRENTLY COMPLAINING OF RIGHT-SIDED INGUINAL PAIN.  PT SUSTAINED ABRASIONS TO RIGHT INGUINAL REGION AND RIGHT CHEEK.  DX: PEDESTRIAN INJURED IN TRAFFIC ACCIDENT - Not Pedestrian\n",
      "21YOF RIDING A SMALL SCOOTER AND STRUCK BY CAR ON L SIDE, PT WAS THEPEDESTRIAN DX:A L HIP AND KNEE CONTU - Not Pedestrian\n",
      "55 YOF PEDESTRIAN WAS STRUCK BY A CYCLIST TRAVELING 15-20MPH.          DX:  TRAUMATIC ICH, EPIDURAL HEMATOMA, RESP FAILURE, SDH. - Not Pedestrian\n",
      "50YOM W/THORACIC & LUMBAR BACK STRAIN S/P PEDESTRIAN HIT BY CAR THAT WAS BACKING UP. STATES WAS SITTING IN A CART WHEN HIT. - Not Pedestrian\n",
      "13 YOM ***, TRIED TO DODGE PEDESTRIAN & FELL C/O ANKLE PAIN DX TRIPLANE ANKLE FRACTURE - Not Pedestrian\n"
     ]
    }
   ],
   "source": [
    "print(\"Untrained model predictions\")\n",
    "print(\"----------------------------\")\n",
    "\n",
    "for text in sample:\n",
    "    # Tokenize text\n",
    "    inputs = tokenizer.encode(text, return_tensors='pt')\n",
    "    # compute logits\n",
    "    logits = model(inputs).logits\n",
    "    # Convert logits to label\n",
    "    predictions = torch.argmax(logits)\n",
    "    \n",
    "    print(text + ' - ' + id2label[predictions.item()])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potentially increase the batch size\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 0.00006 # Size of optimization step\n",
    "batch_size = 4 # number of examples processed per optimization step\n",
    "num_epochs = 10 # number of times the model runs through training data\n",
    "weight_decay = 0.1\n",
    "\n",
    "# Defining the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=weight_decay,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True, \n",
    "    save_total_limit=4,\n",
    "    report_to='tensorboard',\n",
    "    do_eval=True, \n",
    "    logging_strategy='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 189\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 48\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sz/hbk1460n5wdbf8wpmtyd24sc0000gn/T/ipykernel_86085/3979725094.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model, # our peft model\n",
    "    args=training_args, # hyperparameters\n",
    "    train_dataset=results['train'], # training data\n",
    "    eval_dataset=results['test'], # testing data\n",
    "    tokenizer=tokenizer, # The narratives from the training and testing sets are already pre-tokenized. Passing the tokenizer here is primarily used for decoding predictions\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics # Runs on HuggingFace's EvalPrediction object (see compute metrics notes for how this works)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [480/480 02:09, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.703200</td>\n",
       "      <td>0.677842</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.702703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.682000</td>\n",
       "      <td>0.666077</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.712329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.654900</td>\n",
       "      <td>0.625907</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.570200</td>\n",
       "      <td>0.494400</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.827586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.400500</td>\n",
       "      <td>0.469560</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.412100</td>\n",
       "      <td>0.449816</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.867925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.297600</td>\n",
       "      <td>0.608982</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.339000</td>\n",
       "      <td>0.627919</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.272900</td>\n",
       "      <td>0.611603</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.216200</td>\n",
       "      <td>0.662717</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=480, training_loss=0.45486276149749755, metrics={'train_runtime': 130.5719, 'train_samples_per_second': 14.475, 'train_steps_per_second': 3.676, 'total_flos': 35458407838128.0, 'train_loss': 0.45486276149749755, 'epoch': 10.0})"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model predictions\n",
      "----------------------------\n",
      "17YOM PRESENTED AT ED C/O OF PEDESTRIAN STRUCK. PT WAS HELMETED AND RIDING A BICYCLE WHEN A CAR HIT HIM HEAD-ON. PT HIT THE WINDSHIELD AGAINST THE FRONT OF HIS BODY AND LEFT SIDE OF HIS FACE.  DENIES ANY LOSS OF CONSCIOUSNESS. CURRENTLY COMPLAINING OF RIGHT-SIDED INGUINAL PAIN.  PT SUSTAINED ABRASIONS TO RIGHT INGUINAL REGION AND RIGHT CHEEK.  DX: PEDESTRIAN INJURED IN TRAFFIC ACCIDENT - Pedestrian\n",
      "21YOF RIDING A SMALL SCOOTER AND STRUCK BY CAR ON L SIDE, PT WAS THEPEDESTRIAN DX:A L HIP AND KNEE CONTU - Not Pedestrian\n",
      "55 YOF PEDESTRIAN WAS STRUCK BY A CYCLIST TRAVELING 15-20MPH.          DX:  TRAUMATIC ICH, EPIDURAL HEMATOMA, RESP FAILURE, SDH. - Not Pedestrian\n",
      "50YOM W/THORACIC & LUMBAR BACK STRAIN S/P PEDESTRIAN HIT BY CAR THAT WAS BACKING UP. STATES WAS SITTING IN A CART WHEN HIT. - Pedestrian\n",
      "13 YOM ***, TRIED TO DODGE PEDESTRIAN & FELL C/O ANKLE PAIN DX TRIPLANE ANKLE FRACTURE - Not Pedestrian\n"
     ]
    }
   ],
   "source": [
    "model.to('mps')\n",
    "\n",
    "print(\"Trained model predictions\")\n",
    "print(\"----------------------------\")\n",
    "\n",
    "for text in sample:\n",
    "    # Tokenize text\n",
    "    inputs = tokenizer.encode(text, return_tensors='pt').to('mps')\n",
    "    # compute logits\n",
    "    logits = model(inputs).logits\n",
    "    # Convert logits to label\n",
    "    predictions = torch.argmax(logits)\n",
    "    \n",
    "    print(text + ' - ' + id2label[predictions.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the pedestrian samples with all of our data so that we can refer to additional points of data if need be\n",
    "peds = pd.DataFrame(peds, columns=['Narrative_1']).merge(df, on='Narrative_1', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Narrative_1</th>\n",
       "      <th>CPSC_Case_Number</th>\n",
       "      <th>Treatment_Date</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Other_Race</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>Body_Part</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Other_Diagnosis</th>\n",
       "      <th>Body_Part_2</th>\n",
       "      <th>Diagnosis_2</th>\n",
       "      <th>Other_Diagnosis_2</th>\n",
       "      <th>Disposition</th>\n",
       "      <th>Location</th>\n",
       "      <th>Fire_Involvement</th>\n",
       "      <th>Product_1</th>\n",
       "      <th>Product_2</th>\n",
       "      <th>Product_3</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Stratum</th>\n",
       "      <th>PSU</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18 YOM BIBA AFTER BEING STRUCK BY A DUMP TRUCK...</td>\n",
       "      <td>140144086</td>\n",
       "      <td>01/16/2014</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1333.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V</td>\n",
       "      <td>77.0</td>\n",
       "      <td>14.3089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36 YOM BIBA, WAS STRUCK BY AN SUV WHILE RIDING...</td>\n",
       "      <td>140144109</td>\n",
       "      <td>01/16/2014</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5040.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V</td>\n",
       "      <td>77.0</td>\n",
       "      <td>14.3089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61 YOM REPORTS BEING PEDESTRIAN STRUCK BY MV A...</td>\n",
       "      <td>140227568</td>\n",
       "      <td>02/11/2014</td>\n",
       "      <td>61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5040.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V</td>\n",
       "      <td>77.0</td>\n",
       "      <td>14.3089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Narrative_1 CPSC_Case_Number  \\\n",
       "0  18 YOM BIBA AFTER BEING STRUCK BY A DUMP TRUCK...        140144086   \n",
       "1  36 YOM BIBA, WAS STRUCK BY AN SUV WHILE RIDING...        140144109   \n",
       "2  61 YOM REPORTS BEING PEDESTRIAN STRUCK BY MV A...        140227568   \n",
       "\n",
       "  Treatment_Date  Age  Sex  Race Other_Race  Hispanic  Body_Part  Diagnosis  \\\n",
       "0     01/16/2014   18  1.0   3.0   HISPANIC       NaN       76.0       57.0   \n",
       "1     01/16/2014   36  1.0   1.0        NaN       NaN       34.0       57.0   \n",
       "2     02/11/2014   61  1.0   1.0        NaN       NaN       34.0       64.0   \n",
       "\n",
       "  Other_Diagnosis  Body_Part_2  Diagnosis_2 Other_Diagnosis_2  Disposition  \\\n",
       "0             NaN          NaN          NaN               NaN          4.0   \n",
       "1             NaN          NaN          NaN               NaN          4.0   \n",
       "2             NaN          NaN          NaN               NaN          1.0   \n",
       "\n",
       "   Location  Fire_Involvement  Product_1  Product_2  Product_3  Alcohol  Drug  \\\n",
       "0       4.0               0.0     1333.0        0.0        0.0      NaN   NaN   \n",
       "1       4.0               0.0     5040.0        0.0        0.0      NaN   NaN   \n",
       "2       4.0               0.0     5040.0        0.0        0.0      NaN   NaN   \n",
       "\n",
       "  Stratum   PSU   Weight  \n",
       "0       V  77.0  14.3089  \n",
       "1       V  77.0  14.3089  \n",
       "2       V  77.0  14.3089  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peds.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling the data that the model has not seen before\n",
    "unseen_data = peds[~peds['Narrative_1'].isin(labeled_sample['Narrative_1'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying narratives containing pedestrian\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.to('mps')\n",
    "\n",
    "print('Classifying narratives containing pedestrian')\n",
    "print('--------------------------------------------')\n",
    "\n",
    "classifications = []\n",
    "for narrative in unseen_data['Narrative_1']:\n",
    "    # Tokenize text\n",
    "    inputs = tokenizer.encode(narrative, return_tensors='pt').to('mps')\n",
    "    # compute logits\n",
    "    logits = model(inputs).logits\n",
    "    # Convert logits to label\n",
    "    predictions = torch.argmax(logits)\n",
    "    \n",
    "    classifications.append(id2label[predictions.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sz/hbk1460n5wdbf8wpmtyd24sc0000gn/T/ipykernel_86085/73694868.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unseen_data['LLM Classification'] = classifications\n"
     ]
    }
   ],
   "source": [
    "unseen_data['LLM Classification'] = classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1257\n"
     ]
    }
   ],
   "source": [
    "# Randomly sampling 100 of the 1257 samples that our model classified\n",
    "print(len(unseen_data))\n",
    "unseen_data[['Narrative_1', 'LLM Classification']].sample(100, random_state=42).to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df = pd.read_csv('performance_df.csv', index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df['LLM Classification'] = performance_df['LLM Classification'].map(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Narrative_1</th>\n",
       "      <th>LLM Classification</th>\n",
       "      <th>Human Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>6YOM WHO WAS RIDING HIS BIKE AND LOST CONTROL,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>27 YOM W/HELMET SWERVED BIKE TO AVOID PEDESTRI...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>49 YOM DX BACK CONTUSION - S/P BICYCLIST STRUC...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>18YOM W/OPEN FXS OF TIBIA &amp; FIBULA,ABRAS HIP &amp;...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>18YOF BIBEMS AFTER STRUCK BY CAR AND PROPELLED...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>24YOF W/BILAT PUL CONTS,KNEE AVULSION &amp; FACIAL...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>68yom reports being pedestrian struck when he ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>75YOF TRYING TO GET A SPOON FROM THE BACK OF T...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>47 YOF DX RT ORBITAL FLOOR FX/RT SPHENOID SINU...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>19 YOM KNEE SPRAIN, RIDING HIS BIKE AT SCHOOL ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Narrative_1  LLM Classification  \\\n",
       "index                                                                          \n",
       "522    6YOM WHO WAS RIDING HIS BIKE AND LOST CONTROL,...                   1   \n",
       "116    27 YOM W/HELMET SWERVED BIKE TO AVOID PEDESTRI...                   0   \n",
       "56     49 YOM DX BACK CONTUSION - S/P BICYCLIST STRUC...                   0   \n",
       "72     18YOM W/OPEN FXS OF TIBIA & FIBULA,ABRAS HIP &...                   1   \n",
       "1273   18YOF BIBEMS AFTER STRUCK BY CAR AND PROPELLED...                   1   \n",
       "...                                                  ...                 ...   \n",
       "182    24YOF W/BILAT PUL CONTS,KNEE AVULSION & FACIAL...                   1   \n",
       "359    68yom reports being pedestrian struck when he ...                   1   \n",
       "30     75YOF TRYING TO GET A SPOON FROM THE BACK OF T...                   0   \n",
       "32     47 YOF DX RT ORBITAL FLOOR FX/RT SPHENOID SINU...                   0   \n",
       "327    19 YOM KNEE SPRAIN, RIDING HIS BIKE AT SCHOOL ...                   0   \n",
       "\n",
       "       Human Label  \n",
       "index               \n",
       "522              1  \n",
       "116              0  \n",
       "56               0  \n",
       "72               1  \n",
       "1273             1  \n",
       "...            ...  \n",
       "182              1  \n",
       "359              1  \n",
       "30               0  \n",
       "32               0  \n",
       "327              0  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.761     0.795     0.778        44\n",
      "           1      0.833     0.804     0.818        56\n",
      "\n",
      "    accuracy                          0.800       100\n",
      "   macro avg      0.797     0.800     0.798       100\n",
      "weighted avg      0.801     0.800     0.800       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(performance_df['Human Label'], performance_df['LLM Classification'], digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1ad436d90>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(performance_df['Human Label'], performance_df['LLM Classification']))\n",
    "cm.plot(cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['24YOM PRESENTED TO ED C/O PEDESTRAIN STRUCK, PT STATED HE WAS A PASSENGER ON ELECTRIC BIKE AND WAS HIT BY A TURNING MOTOR VEHICLE. REPORTED HE FELL ON L SIDE ON CEMENT. C/O R LEG PAIN AND ABRASIONS TO KNEE, DX; LEG PAIN, KNEE PAIN, MVA',\n",
       "       '14YOM PRESENTED TO ED C/O PEDESTRAIN STRUCK, PT STATED HE WAS ON THE BACK OF MOPED AND WAS STRUCK BY A CAR. ABRASION TO KNEE DX; FALL',\n",
       "       '46YOM, C/O HIP PAIN, OPENING GATE WHEN CAR HE WAS PULLING ON TRAILER BEGAN TO ROLL & PINNED HIS LEG BETWEEN GATE & VEHICLE, TAKES ***  DX: RIGHT LOWER EXTREMTIY CRUSH INJURY TRUCK VS PEDESTRIAN, HX AFIB, CHRONIC ANTICOAGULATION THERAPY, NO FRACTURE',\n",
       "       '26YOM PRESENTS FOR PEDESTRIAN STRUCK, WAS ON MOTORIZED BIKE AND GOT HIT BY CAR, C/O LT LOWER EXTREMITY PAIN DX: ANKLE FRACTURE, LOWER LEG ABRASIONS, ANKLE ABRASIONS',\n",
       "       '32YOM PEDESTRIAN STRUCK BY A CAR WHILE RIDING AN ELECTRIC SKATEBOARD. + BLOOD IN R EARDX HEMORRHAGE SUBDURAL TRAUMATIC W/O LOC',\n",
       "       '73YOF WAS HIT IN THE BACK BY A BICYCLIST WHILE SHE WAS WALKING ON THE RIVERBED. DX: BICYCLIST VERSUS PEDESTRIAN, R FRONTAL SUBDURAL HEMATOMA, B/L FRONTAL PARIETAL SUBARACHNOID HEMORRRHAGE, L 5TH-10TH RIB FRACTURES, LEFT OCCIPITAL HEMATOMA, LEFT FOREARM/HAND ABRASION, MULTICOMPARTMENT INTRACRANIAL HEMORRHAGE',\n",
       "       '! 35 YOM. PT RIDING MOTORIZED BICYCLE AND STRUCK BY CAR TRAVELING 10 MPH, COMPLAINING OF ALL BODY PAIN. + METH ON UTOX. ETOH 0.004. DX: C5 CERVICAL FRACTURE, ALTERED MENTAL STATE, MOTOR VEHICLE COLLISION, TOE LACERATION, MOTOR VEHICLE COLLISION WITH PEDESTRAIN, METHAMPHETAMINE ABUSE, LACERATION OF DORSUM OF FOOT, ACUTE ALCOHOL INTOXICATION.',\n",
       "       '30 YOF REPORTS BEING PEDESTRAIN STRUCK BY BICYCLE 2 HRS AGO AND FELLTO GROUND, HAS CUT TO SCALP. DX HIT BY BICYCLE, SCALP LACERATION%',\n",
       "       '26YOM REPORTS HE WAS HIT BY A CAR WHILE RIDING A MOPED. PATIENT STATES HE FELL AND HIT HIS HEAD. DX HEAD INJURY, PEDESTRIAN STRUCK, ADMIT.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df[(performance_df['LLM Classification']==1) & (performance_df['Human Label']==0)]['Narrative_1'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Model Notes\n",
    "- The model seemed to misclassify some obvious ones where a biker was struck by a car. It would be good to feed it more of these as examples\n",
    "- Some edge cases of electric scooters and other electric vehicles (dirt bikes, mopeds etc.) would be good to feed to the model. It was having some diffculty there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan to Strengthen the Model\n",
    "> The current model was trained on an initial set of 237 human-labeled samples. It achieved an overall accuracy of 80.0%, with a precision of 83.3% on samples labeled as pedestrian injuries. The following steps will be implemented to further strengthen and refine the model.\n",
    "\n",
    "1. Combine labeled data: Merge the original 237 labeled samples with the 100 newly labeled ones, resulting in a training/validation set of 337 examples.\n",
    "1. Create a holdout evaluation set by stratifying 150 samples:\n",
    "    * 50 containing the word or some variation of the word “pedestrian”\n",
    "    * 50 containing “struck by” or “hit by” \n",
    "    * 50 containing both\n",
    "\n",
    "    These samples will not be among the 337 samples used for training and will be manually labeled and reserved exclusively for final evaluation.\n",
    "3. Train the model: Perform a new train/validation split and fine-tune the model accordingly.\n",
    "4. Generate predictions using softmax probabilities instead of argmax. Then proceed with one of two approaches:\n",
    "* **4.1. Keep existing model and tune threshold:** \n",
    "    * Classify a narrative as a pedestrian injury only if the model assigns a probability ≥ 80% (or another calibrated value). Evaluate this model on the holdout set to measure precision and overall performance.\n",
    "* **4.2. Add additional data based on softmax probablities:**\n",
    "    * Auto-label: Add all of the data where the model was ≥ 90% and ≤ 10% sure to expand the dataset.\n",
    "    * Manual label: Add ~50 borderline predictions (45–55% confidence) to refine the model near the decision boundary.\n",
    "    * Retrain the model with the expanded dataset and evaluate on the same holdout set.\n",
    "5. Compare results from steps 4.1 and 4.2 and select the version that delivers the best precision and overall performance as the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Combine labeled data to make the train/validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the two, only keeping the narrative and the human label\n",
    "train_validation = pd.concat(\n",
    "    [labeled_sample[['Narrative_1', 'Pedestrian Label']].rename(columns={'Pedestrian Label': 'Human Label'}),\n",
    "     performance_df[['Narrative_1', 'Human Label']]],\n",
    "    axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Holdout Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter narratives that contain relevant keywords related to pedestrian activity or motor vehicle involvement\n",
    "search_words = [\n",
    "    \"walking\", \"walk\", \"jogging\", \"jog\", \"running\", \"run\", \"on foot\", \"bystander\",\n",
    "    \"standing\", \"biking\", \"bike\", \"roller skating\", \"roller skates\", \"skateboarding\",\n",
    "    \"skateboard\", \"scootering\", \"scooter\", \"pedestr\", \"pedst\", \"struck by\", \"hit by\"\n",
    "]\n",
    "\n",
    "filtered_df = df[df['Narrative_1'].str.contains('|'.join(search_words), case=False, na=False)]\n",
    "\n",
    "# ~470,000 samples contain at least one keyword (~6.25 hours to run locally)\n",
    "len(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96128"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Filter further by location codes of interest (e.g., street or highway)\n",
    "filtered_df = filtered_df[filtered_df['Location'].isin([4, 5])]\n",
    "\n",
    "# ~96,000 samples remain (~76.5 minutes to run locally)\n",
    "print(len(filtered_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19489"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Focus on narratives that explicitly mention \"pedestrian\", \"struck by\", or \"hit by\"\n",
    "filtered_df = filtered_df[filtered_df['Narrative_1'].str.contains('|'.join([\"pedestr\", \"pedst\", \"struck by\", \"hit by\"]), case=False, na=False)]\n",
    "\n",
    "# ~20,000 high-priority samples (~15 minutes to run locally)\n",
    "print(len(filtered_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This subset of ~20,000 samples contains location-relevant narratives with keywords most likely to reflect pedestrian injuries involving motor vehicles. This will serve as the primary dataset for local experimentation. In future iterations, model weights may be exported and applied at scale on larger datasets using cloud resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19226"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Excluding data that out model will be trained on\n",
    "filtered_df = filtered_df[~filtered_df['Narrative_1'].isin(train_validation['Narrative_1'])]\n",
    "\n",
    "# There are 19,226 samples that are not in our train/validation set\n",
    "# NOTE: Some data in our train_validation set are not in our original filtered_df since the location codes outside of 4 and 5 were not excluded initially\n",
    "len(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask that contains all of the narratives containing pedestrian\n",
    "pedestrian_mask = filtered_df['Narrative_1'].str.contains('pedst|pedestr', case=False, na=False)\n",
    "# Mask containing all of the narratives containing struck by/hit by\n",
    "struck_hit_mask = filtered_df['Narrative_1'].str.contains('struck by|hit by', case=False, na=False)\n",
    "\n",
    "# df containing 50 \"pedestrian\" samples that don't contain \"struck/hit\" by\n",
    "group_a = filtered_df[pedestrian_mask & ~struck_hit_mask].sample(50, random_state=42)\n",
    "\n",
    "# df containing 50 \"struck/hit by\" samples that dont contain \"pedestrian\"\n",
    "group_b = filtered_df[struck_hit_mask & ~pedestrian_mask].sample(50, random_state=42)\n",
    "\n",
    "# df containing 50 samples where both \"pedestrian\" and \"struck/hit by\" are present in the narrative\n",
    "group_c = filtered_df[struck_hit_mask & pedestrian_mask].sample(50, random_state=42)\n",
    "\n",
    "# Creating flags to test the models performance among each group\n",
    "group_a['group'] = 'group_a'\n",
    "group_b['group'] = 'group_b'\n",
    "group_c['group'] = 'group_c'\n",
    "\n",
    "# Holdout set containing all three groups\n",
    "holdout = pd.concat([group_a, group_b, group_c], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPSC_Case_Number</th>\n",
       "      <th>Treatment_Date</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Other_Race</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>Body_Part</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Other_Diagnosis</th>\n",
       "      <th>Body_Part_2</th>\n",
       "      <th>Diagnosis_2</th>\n",
       "      <th>Other_Diagnosis_2</th>\n",
       "      <th>Disposition</th>\n",
       "      <th>Location</th>\n",
       "      <th>Fire_Involvement</th>\n",
       "      <th>Product_1</th>\n",
       "      <th>Product_2</th>\n",
       "      <th>Product_3</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Narrative_1</th>\n",
       "      <th>Stratum</th>\n",
       "      <th>PSU</th>\n",
       "      <th>Weight</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1373638</th>\n",
       "      <td>170957638</td>\n",
       "      <td>09/24/2017</td>\n",
       "      <td>52</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5040.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52YF HELM'D BICYCLIST CRASHED INTO PEDESTRIAN&amp;...</td>\n",
       "      <td>V</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.1828</td>\n",
       "      <td>group_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870136</th>\n",
       "      <td>220159454</td>\n",
       "      <td>01/25/2022</td>\n",
       "      <td>24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5040.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24 YOF IN MVA , PEDESTRIAN STRUCK AND INJ LEG ...</td>\n",
       "      <td>V</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17.2223</td>\n",
       "      <td>group_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007698</th>\n",
       "      <td>220705908</td>\n",
       "      <td>06/09/2022</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5040.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12YOM BROUGHT IN BY AMBULANCE AFTER A PEDESTRI...</td>\n",
       "      <td>C</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6.6676</td>\n",
       "      <td>group_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703697</th>\n",
       "      <td>151238381</td>\n",
       "      <td>11/18/2015</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5040.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40 YOM DX DISPLACED FX OF LT TIBIAL SPINE - S/...</td>\n",
       "      <td>V</td>\n",
       "      <td>57.0</td>\n",
       "      <td>16.5650</td>\n",
       "      <td>group_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849328</th>\n",
       "      <td>160538697</td>\n",
       "      <td>05/12/2016</td>\n",
       "      <td>25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>LEG/MOUTH PAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5040.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25 YOF DX LEG/MOUTH PAIN - S/P PT PEDESTRIAN S...</td>\n",
       "      <td>V</td>\n",
       "      <td>57.0</td>\n",
       "      <td>14.6504</td>\n",
       "      <td>group_a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CPSC_Case_Number Treatment_Date  Age  Sex  Race Other_Race  Hispanic  \\\n",
       "1373638        170957638     09/24/2017   52  2.0   0.0        NaN       NaN   \n",
       "2870136        220159454     01/25/2022   24  2.0   4.0        NaN       2.0   \n",
       "3007698        220705908     06/09/2022   12  1.0   0.0        NaN       0.0   \n",
       "703697         151238381     11/18/2015   40  1.0   2.0        NaN       NaN   \n",
       "849328         160538697     05/12/2016   25  2.0   2.0        NaN       NaN   \n",
       "\n",
       "         Body_Part  Diagnosis Other_Diagnosis  Body_Part_2  Diagnosis_2  \\\n",
       "1373638       75.0       62.0             NaN          NaN          NaN   \n",
       "2870136       37.0       64.0             NaN          NaN          NaN   \n",
       "3007698       75.0       52.0             NaN          NaN          NaN   \n",
       "703697        36.0       57.0             NaN          NaN          NaN   \n",
       "849328        81.0       71.0  LEG/MOUTH PAIN          NaN          NaN   \n",
       "\n",
       "        Other_Diagnosis_2  Disposition  Location  Fire_Involvement  Product_1  \\\n",
       "1373638               NaN          1.0       4.0               0.0     5040.0   \n",
       "2870136               NaN          1.0       4.0               0.0     5040.0   \n",
       "3007698               NaN          4.0       4.0               0.0     5040.0   \n",
       "703697                NaN          1.0       4.0               0.0     5040.0   \n",
       "849328                NaN          1.0       4.0               0.0     5040.0   \n",
       "\n",
       "         Product_2  Product_3  Alcohol  Drug  \\\n",
       "1373638        0.0        0.0      NaN   NaN   \n",
       "2870136        0.0        0.0      0.0   0.0   \n",
       "3007698        0.0        0.0      0.0   0.0   \n",
       "703697         0.0        0.0      NaN   NaN   \n",
       "849328         0.0        0.0      NaN   NaN   \n",
       "\n",
       "                                               Narrative_1 Stratum   PSU  \\\n",
       "1373638  52YF HELM'D BICYCLIST CRASHED INTO PEDESTRIAN&...       V  21.0   \n",
       "2870136  24 YOF IN MVA , PEDESTRIAN STRUCK AND INJ LEG ...       V  38.0   \n",
       "3007698  12YOM BROUGHT IN BY AMBULANCE AFTER A PEDESTRI...       C  37.0   \n",
       "703697   40 YOM DX DISPLACED FX OF LT TIBIAL SPINE - S/...       V  57.0   \n",
       "849328   25 YOF DX LEG/MOUTH PAIN - S/P PT PEDESTRIAN S...       V  57.0   \n",
       "\n",
       "          Weight    group  \n",
       "1373638  16.1828  group_a  \n",
       "2870136  17.2223  group_a  \n",
       "3007698   6.6676  group_a  \n",
       "703697   16.5650  group_a  \n",
       "849328   14.6504  group_a  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Features({\n",
    "    'text': Value('string'),\n",
    "    'labels': ClassLabel(names=[\"Not Pedestrian\", \"Pedestrian\"])\n",
    "})\n",
    "\n",
    "dataset = Dataset.from_pandas(\n",
    "    df=train_validation.rename(columns={'Narrative_1':'text', 'Human Label': 'labels'}).reset_index(drop=True),\n",
    "    features=features\n",
    ")\n",
    "\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42, stratify_by_column='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 269\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 68\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 269/269 [00:00<00:00, 2190.43 examples/s]\n",
      "Map: 100%|██████████| 68/68 [00:00<00:00, 4493.17 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Initializing tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# defining the tokenization function\n",
    "def tokenize(sample):\n",
    "    return tokenizer(\n",
    "        sample['text'],\n",
    "        # padding='max_length',\n",
    "        truncation=True\n",
    "    )\n",
    "    \n",
    "results = dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "id2label = {0: \"Not Pedestrian\", 1: \"Pedestrian\"}\n",
    "label2id = {\"Not Pedestrian\":0, \"Pedestrian\": 1}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels = 2,\n",
    "    id2label = id2label,\n",
    "    label2id = label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
