{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DevJGraham/neiss_pedestrian_accounts/blob/working/neiss_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY_ynnbF1XT2"
      },
      "source": [
        "# Neiss Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notebook Instructions\n",
        "\n",
        "1. **If you're using Google Colab**, select a **T4 GPU** runtime for optimal performance.\n",
        "> *Note: Training will still run on CPU, but it will be significantly slower. You may need to upgrade to Colab Pro if you exceed T4 availability on the free tier.*\n",
        "2. **Run the pip install cell** to install all required dependencies.\n",
        "These are not automatically available when a new runtime starts\n",
        "3. **Restart the runtime** after the installations complete\n",
        "4. **Run the remaining notebook cells**, skipping the pip installs"
      ],
      "metadata": {
        "id": "_05GAYPOd4C0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FebkAyq-UtWv"
      },
      "outputs": [],
      "source": [
        "!pip install evaluate numpy==1.26.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvl_Wj5964Lt"
      },
      "outputs": [],
      "source": [
        "# Core libraries for data handling and manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Visualization tools for performance analysis\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Scikit-learn metrics for evaluating classification performance\n",
        "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay, precision_recall_curve\n",
        "\n",
        "# Hugging Face datasets and transformers for model training and evaluation\n",
        "from datasets import Dataset, ClassLabel, Features, Value\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "from evaluate import load\n",
        "\n",
        "# PyTorch for model definition and GPU acceleration\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtGJ2aay5IIL"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2JQbFAl5N9G"
      },
      "outputs": [],
      "source": [
        "# Mount onto your dirve\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGnGq-z6WLEH"
      },
      "outputs": [],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "wDTWP646SNUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Navigate to the folder where this project is on your drive\n",
        "cd drive/MyDrive/NEISS/"
      ],
      "metadata": {
        "id": "QAaB3nqOSPSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in downloaded neiss data as df\n",
        "df = pd.read_csv('./neiss_data/neiss_2014-2024.csv', index_col=0)"
      ],
      "metadata": {
        "id": "VNVBXGi9o_oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "--pabkXQpWbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "id": "HuQpdE4Ly37R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndJ4Lfk828if"
      },
      "outputs": [],
      "source": [
        "# Drop records with missing Narrative_1 data\n",
        "df.drop(df[df['Narrative_1'].isnull()].index, axis=0, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T06BeW5Z65Pv"
      },
      "source": [
        "# Fine Tuning Distil-BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu_83Iq37JAj"
      },
      "source": [
        "## 1. Read in hand labeled data and add informative data to the Narrative"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading in the pre-labeled data\n",
        "labeled_df = pd.read_csv(\"./neiss_data/labeled_data/hand_labeled_samples_487.csv\")"
      ],
      "metadata": {
        "id": "xqvqwkOoeK43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to concatentate all useful information along with the narrative\n",
        "def concat_narrative(row):\n",
        "  body_part = row['Body_Part']\n",
        "  diagnosis = row['Diagnosis']\n",
        "  disposition = row['Disposition']\n",
        "  product = row['Product_1']\n",
        "  narrative = row['Narrative_1']\n",
        "\n",
        "  return f\"Product Code: {product}. Body Part Code: {body_part}. Diagnosis Code: {diagnosis}. Disposition Code: {disposition}. Narrative: {narrative}\""
      ],
      "metadata": {
        "id": "STOusns7hMHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_df['concat_narrative'] = labeled_df.apply(concat_narrative, axis=1)\n",
        "labeled_df['concat_narrative']"
      ],
      "metadata": {
        "id": "VgceilVxjXQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Filter down original data frame to a more concentrated search"
      ],
      "metadata": {
        "id": "NVqDFfYIe3Fs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soQMiIsHYSoK"
      },
      "outputs": [],
      "source": [
        "# Create a filtered dataframe where only the Location codes 4 and 5 (streets and highways) are included\n",
        "filtered_df = df[df['Location'].isin([4, 5])]\n",
        "\n",
        "# ~330,000 samples remain\n",
        "print(len(filtered_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4p4_cQwYL2T"
      },
      "outputs": [],
      "source": [
        "# # There are many more words that we could include in the filter\n",
        "# # These would be good to include later, however, for the sake of simplicity, we will only include the search words in the next cell\n",
        "# search_words = [\n",
        "#     \"walking\", \"walk\", \"jogging\", \"jog\", \"running\", \"run\", \"on foot\", \"bystander\",\n",
        "#     \"standing\", \"biking\", \"bike\", \"roller skating\", \"roller skates\", \"skateboarding\",\n",
        "#     \"skateboard\", \"scootering\", \"scooter\", \"pedestr\", \"pedst\", \"struck by\", \"hit by\"\n",
        "# ]\n",
        "\n",
        "# filtered_df = filtered_df[filtered_df['Narrative_1'].str.contains('|'.join(search_words), case=False, na=False)]\n",
        "\n",
        "# len(filtered_df) # ~96,000 samples would remain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d8wOQVUYxfa"
      },
      "outputs": [],
      "source": [
        "# Filter df further to only include narratives that include \"pedestrian\" (or variation of spelling), \"struck by\", or \"hit by\"\n",
        "filtered_df = filtered_df[filtered_df['Narrative_1'].str.contains('|'.join([\"pedestr\", \"pedst\", \"struck by\", \"hit by\"]), case=False, na=False)]\n",
        "\n",
        "# ~20,000 high-priority samples\n",
        "print(len(filtered_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPtDwooLY1iC"
      },
      "outputs": [],
      "source": [
        "# Excluding data that the model will be trained on\n",
        "filtered_df = filtered_df[~filtered_df['Narrative_1'].isin(labeled_df['Narrative_1'])]\n",
        "\n",
        "# There are 19,076 samples that are not in our train/validation set\n",
        "# NOTE: Some data in our labeled_df are not in the filtered_df since the location codes outside of 4 and 5 were not excluded when pulling data to be hand labeled\n",
        "# filtered_df contains the samples that we can run the fine-tuned model on to create the cohort\n",
        "len(filtered_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aAUW60-Y3zC"
      },
      "outputs": [],
      "source": [
        "# Mask that contains all of the narratives containing pedestrian\n",
        "pedestrian_mask = filtered_df['Narrative_1'].str.contains('pedst|pedestr', case=False, na=False)\n",
        "# Mask containing all of the narratives containing struck by/hit by\n",
        "struck_hit_mask = filtered_df['Narrative_1'].str.contains('struck by|hit by', case=False, na=False)\n",
        "\n",
        "# df containing 50 \"pedestrian\" samples that don't contain \"struck/hit\" by\n",
        "group_a = filtered_df[pedestrian_mask & ~struck_hit_mask].sample(50, random_state=42)\n",
        "\n",
        "# df containing 50 \"struck/hit by\" samples that dont contain \"pedestrian\"\n",
        "group_b = filtered_df[struck_hit_mask & ~pedestrian_mask].sample(50, random_state=42)\n",
        "\n",
        "# df containing 50 samples where both \"pedestrian\" and \"struck/hit by\" are present in the narrative\n",
        "group_c = filtered_df[struck_hit_mask & pedestrian_mask].sample(50, random_state=42)\n",
        "\n",
        "# Creating flags to test the models performance among each group\n",
        "group_a['group'] = 'group_a'\n",
        "group_b['group'] = 'group_b'\n",
        "group_c['group'] = 'group_c'\n",
        "\n",
        "# Holdout set containing all three groups\n",
        "holdout = pd.concat([group_a, group_b, group_c], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAK5aN_DY6Fd"
      },
      "outputs": [],
      "source": [
        "holdout.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcfZnI2oZBhO"
      },
      "source": [
        "## 3. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_df.head(3)"
      ],
      "metadata": {
        "id": "3o93eh88qeB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnMUiXvhZGt8"
      },
      "outputs": [],
      "source": [
        "# This is the cell that is affected by the numpy downgrade. If you run into an issue here, restart your runtime session and run the cells in the notebook again\n",
        "\n",
        "# In order to stratify by the labels, you must set them as features in the dataset\n",
        "features = Features({\n",
        "    'text': Value('string'),\n",
        "    'labels': ClassLabel(names=[\"Not Pedestrian\", \"Pedestrian\"])\n",
        "})\n",
        "\n",
        "# Create a huggingface dataset only containing the text (concat_narrative) and the labels (Human Label)\n",
        "dataset = Dataset.from_pandas(\n",
        "    df=labeled_df.rename(columns={'concat_narrative':'text', 'Human Label': 'labels'}).reset_index(drop=True)[['labels','text']],\n",
        "    features=features\n",
        ")\n",
        "\n",
        "# Split the data into a train and validation set, stratifying by the labels\n",
        "dataset = dataset.train_test_split(test_size=0.2, seed=42, stratify_by_column='labels')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hM-Wc2nZIoH"
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46Cj9ckHZKmL"
      },
      "outputs": [],
      "source": [
        "pretrained_model = \"bert-base-uncased\" # Set the pretrained model that will be used\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model) # Initialize the tokenizer\n",
        "\n",
        "# defining the tokenization function\n",
        "def tokenize(sample):\n",
        "    return tokenizer(\n",
        "        sample['text'],\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "# Tokenize the dataset saving it as results\n",
        "results = dataset.map(tokenize, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UNynELtZMf5"
      },
      "outputs": [],
      "source": [
        "id2label = {0: \"Not Pedestrian\", 1: \"Pedestrian\"}\n",
        "label2id = {\"Not Pedestrian\":0, \"Pedestrian\": 1}\n",
        "\n",
        "# Setting up the classification head with the two labels\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    pretrained_model,\n",
        "    num_labels = 2,\n",
        "    id2label = id2label,\n",
        "    label2id = label2id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRGSQW8BZPC0"
      },
      "outputs": [],
      "source": [
        "# Load evaluation metrics\n",
        "accuracy = load(\"accuracy\")\n",
        "precision = load(\"precision\")\n",
        "recall = load(\"recall\")\n",
        "f1_score = load(\"f1\")\n",
        "\n",
        "# Define a metric function for evaluation\n",
        "def compute_metrics(p):\n",
        "    pred = np.argmax(p.predictions, axis=1)\n",
        "    labels = p.label_ids\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy.compute(predictions=pred, references=labels)['accuracy'],\n",
        "        \"precision\": precision.compute(predictions=pred, references=labels, average='binary')['precision'],\n",
        "        \"recall\": recall.compute(predictions=pred, references=labels, average='binary')['recall'],\n",
        "        \"f1\": f1_score.compute(predictions=pred, references=labels, average='binary')['f1'],\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qKismoqZRvQ"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "lr = 0.00004 # Size of optimization step\n",
        "batch_size = 4 # number of examples processed per optimization step\n",
        "num_epochs = 10 # number of times the model runs through training data\n",
        "weight_decay = 0.1\n",
        "\n",
        "# Defining the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    learning_rate=lr,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    weight_decay=weight_decay,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_only_model=True,\n",
        "    load_best_model_at_end=False, # If False we will have to load the best model by hand based on the model checkpoints in the results directory\n",
        "    save_total_limit=10,\n",
        "    report_to='tensorboard',\n",
        "    do_eval=True,\n",
        "    logging_strategy='epoch',\n",
        "    overwrite_output_dir=True,\n",
        "    metric_for_best_model=\"accuracy\", # We care most about accuracy for defining a cohort.\n",
        "    label_smoothing_factor=0.1 # To help with not having the model be overly confident in its predictions\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IITy0JJFZT7f"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args, # hyperparameters\n",
        "    train_dataset=results['train'], # training data\n",
        "    eval_dataset=results['test'], # validation data\n",
        "    tokenizer=tokenizer, # The narratives from the training and testing sets are already pre-tokenized. Passing the tokenizer here is primarily used for decoding predictions\n",
        "    data_collator=data_collator, # Dynamically pads each tokenized batch\n",
        "    compute_metrics=compute_metrics # Runs on HuggingFace's EvalPrediction object (see compute metrics notes for how this works)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnisSjEgZVr2"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CUDA is a software layer that gives direct access to the GPU's virtual instruction set and parallel computational elements for the execution of compute kernels\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "L9Pfxg-7d7iR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best model based on the metric_for_best_model argument in the TrainingArguments\n",
        "print(trainer.state.best_model_checkpoint)"
      ],
      "metadata": {
        "id": "dAPzkaH_Dzy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace with whatever checkpoint you decide\n",
        "# This will change after each new model training\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"./results/checkpoint-294\")"
      ],
      "metadata": {
        "id": "MCn7QdTl6NTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sanity Check\n",
        "Making sure that the model performs well on the training set\n",
        "\n",
        "We would expect this to be at or near 100% accuracy"
      ],
      "metadata": {
        "id": "V_25bJX9luTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to evaluation mode (disables dropout and gradient tracking for layers that behave differently during training)\n",
        "model.eval()\n",
        "\n",
        "# Move the model to Compute Unified Device Architecture (cuda), a parallel computing platform and application programming interface (API) model created by NVIDIA\n",
        "model.to('cuda')\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    results['train'].remove_columns(['text']),\n",
        "    batch_size=8,\n",
        "    collate_fn=data_collator\n",
        ")\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad(): # Does not track gradients for evaluation\n",
        "  for batch in train_loader:\n",
        "    batch = {k: v.to('cuda') for k, v in batch.items()}\n",
        "    outputs = model(**batch)\n",
        "    preds = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "    all_preds.extend(preds.cpu().numpy())\n",
        "    all_labels.extend(batch['labels'].cpu().numpy())\n",
        "\n",
        "print(classification_report(all_labels, all_preds))"
      ],
      "metadata": {
        "id": "Y_mGvfgVpUU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Model on Test Set (Argmax)"
      ],
      "metadata": {
        "id": "A5XVK271mX2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to evaluation mode (disables dropout and gradient tracking for layers that behave differently during training)\n",
        "model.eval()\n",
        "\n",
        "# Move the model to Compute Unified Device Architecture (cuda), a parallel computing platform and application programming interface (API) model created by NVIDIA\n",
        "model.to('cuda')\n",
        "\n",
        "# Loading the data to be batched and collated the same way during eval as it was during training\n",
        "train_loader = DataLoader(\n",
        "    results['test'].remove_columns(['text']),\n",
        "    batch_size=8,\n",
        "    collate_fn=data_collator\n",
        ")\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad(): # Does not track gradients for evaluation\n",
        "  for batch in train_loader:\n",
        "    # Move each tensor in the batch to the GPU\n",
        "    batch = {k: v.to('cuda') for k, v in batch.items()}\n",
        "\n",
        "    # Run the model forward pass and get output logits\n",
        "    outputs = model(**batch)\n",
        "\n",
        "    # Select the index of the highest logit as the predicted class\n",
        "    preds = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "    all_preds.extend(preds.cpu().numpy())\n",
        "    all_labels.extend(batch['labels'].cpu().numpy())\n",
        "\n",
        "print(classification_report(all_labels, all_preds))"
      ],
      "metadata": {
        "id": "4mdHb-6-d1We"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Model on Test Set (Softmax)"
      ],
      "metadata": {
        "id": "bYh30AG9mqT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to evaluation mode (disables dropout and gradient tracking for layers that behave differently during training)\n",
        "model.eval()\n",
        "\n",
        "# Move the model to Compute Unified Device Architecture (cuda), a parallel computing platform and application programming interface (API) model created by NVIDIA\n",
        "model.to('cuda')\n",
        "\n",
        "# Loading the data to be batched and collated the same way during eval as it was during training\n",
        "train_loader = DataLoader(\n",
        "    results['test'].remove_columns(['text']),\n",
        "    batch_size=8,\n",
        "    collate_fn=data_collator\n",
        ")\n",
        "\n",
        "y_proba = []\n",
        "y_true = []\n",
        "\n",
        "with torch.no_grad(): # Does not track gradients for evaluation\n",
        "  for batch in train_loader:\n",
        "    # Move each tensor in the batch to the GPU\n",
        "    batch = {k: v.to('cuda') for k, v in batch.items()}\n",
        "\n",
        "    # Run the model forward pass and get output logits\n",
        "    outputs = model(**batch)\n",
        "\n",
        "    # Select the index of the highest logit as the predicted class\n",
        "    probs = F.softmax(outputs.logits, dim=1)[:, 1] # Takes the 0th batch and the 1st predicted probability (pedestrian) from the tensor\n",
        "\n",
        "    y_proba.extend(probs.cpu().numpy())\n",
        "    y_true.extend(batch['labels'].cpu().numpy())"
      ],
      "metadata": {
        "id": "76BxQ2ilDzEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, thresholds = precision_recall_curve(y_true, y_proba)\n",
        "# Plot precision and recall vs threshold\n",
        "plt.plot(thresholds, precision[:-1], label=\"Precision\", color=\"blue\")\n",
        "plt.plot(thresholds, recall[:-1], label=\"Recall\", color=\"red\")\n",
        "plt.xlabel(\"Threshold\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Precision and Recall vs Threshold\")\n",
        "plt.legend()\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "1n85kvoPr8L1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance of model when we set the cutoff for the probability to be 0.95\n",
        "# Note, this current model is predicting very confidently, which is why we have to set the cutoff to be so high before we notice any change to the metrics\n",
        "print(classification_report(y_true, (np.array(y_proba)>0.95).astype(int)))"
      ],
      "metadata": {
        "id": "pdvaY4-ZuIfr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}